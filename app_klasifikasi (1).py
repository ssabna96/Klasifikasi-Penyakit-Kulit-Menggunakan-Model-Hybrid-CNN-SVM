# -*- coding: utf-8 -*-
"""app_klasifikasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15H1nCKm2UKkMgMi75ERyG7Kgdv5gxgAk
"""

import streamlit as st
import numpy as np
from tensorflow.keras.models import load_model, Model
from PIL import Image
import joblib
import requests
import os

# ====================================================
# FUNCTION: DOWNLOAD FILE BESAR DARI GOOGLE DRIVE
# ====================================================
def gdrive_download(file_id, destination):
    URL = "https://drive.google.com/uc?export=download"

    session = requests.Session()
    response = session.get(URL, params={'id': file_id}, stream=True)

    # untuk file >100MB (butuh token konfirmasi)
    def get_confirm_token(response):
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                return value
        return None

    token = get_confirm_token(response)

    if token:
        response = session.get(URL, params={'id': file_id, 'confirm': token}, stream=True)

    # download file
    with open(destination, "wb") as f:
        for chunk in response.iter_content(32768):
            if chunk:
                f.write(chunk)

    return destination

# ====================================================
# LOAD CNN FEATURE EXTRACTOR
# ====================================================
@st.cache_resource
def load_cnn():
    CNN_FILE_ID = "https://drive.google.com/file/d/1RuGjNcW_Yi1MTjmgQymTKxP9594uzm4d/view?usp=drive_link"     # <â”€â”€ GANTI DENGAN ID CNN H5 KAMU
    cnn_path = gdrive_download(CNN_FILE_ID, "model cnn [85:15] 0,35.h5")

    cnn = load_model(cnn_path)
    feature_extractor = Model(
        inputs=cnn.input,
        outputs=cnn.get_layer("feature_layer").output
    )
    return feature_extractor

# ====================================================
# LOAD SVM + SCALER
# ====================================================
@st.cache_resource
def load_svm():
    svm = joblib.load("svm_ovo_model.pkl")
    scaler = joblib.load("feature_scaler.pkl")
    return svm, scaler

# ====================================================
# LOAD MODELS
# ====================================================
feature_extractor = load_cnn()
svm, scaler = load_svm_scaler()

# ====================================================
# STREAMLIT UI
# ====================================================
st.title("Klasifikasi Penyakit Kulit â€¢ CNN + SVM (Model via Google Drive)")
st.write("Model CNN + SVM otomatis didownload dari Google Drive saat dijalankan.")

uploaded_file = st.file_uploader("Upload gambar kulit", type=["jpg", "jpeg", "png"])

if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")
    st.image(img, caption="Gambar diupload", width=250)

    # ===== PREPROCESSING =====
    img = img.resize((224, 224))
    img_arr = np.array(img) / 255.0
    img_arr = np.expand_dims(img_arr, axis=0)

    # ===== EKSTRAKSI FITUR CNN =====
    features = feature_extractor.predict(img_arr)

    # ===== NORMALISASI =====
    features_scaled = scaler.transform(features)

    # ===== PREDIKSI SVM =====
    pred = svm.predict(features_scaled)
    label = pred[0]     # sudah berupa angka kelas

    st.subheader("Hasil Prediksi")
    st.success(f"ðŸ“Œ Kelas Prediksi: **{label}**")